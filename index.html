<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Visual Jenga is a new task for scene understanding where, given a single image, the goal is to sequentially remove objects one at a time while maintaining scene stability. We introduce a simple baseline that uses a large generative model and counterfactual inpainting to determine the removal order.">
  <meta property="og:image" content="https://visualjenga.github.io/static/images/teaser.png">
  <meta name="keywords" content="Visula Jenga, Scene Understanding, Counterfactual Inpainting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Visual Jenga: Discovering Object Dependencies via Counterfactual Inpainting</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NW3BQPT3');</script>
  <!-- End Google Tag Manager -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/visual_jenga.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Visual Jenga: Discovering Object Dependencies via Counterfactual Inpainting</h1>
          <div class="authors-grid">
            <div class="author-name"><a href="https://anandbhattad.github.io/">Anand Bhattad</a></div>
            <div class="author-name"><a href="https://konpat.notion.site/">Konpat Preechakul</a></div>
            <div class="author-name"><a href="https://people.eecs.berkeley.edu/~efros/">Alexei A. Efros</a></div>
            <div class="author-affil">TTI-Chicago</div>
            <div class="author-affil">UC Berkeley</div>
            <div class="author-affil">UC Berkeley</div>
          </div>                  
          <br>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./static/Visual_Jenga.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.21770"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div> -->

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay loop playsinline controls height="100%">
        <source src="./static/videos/teaser.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-justified">
        <br>
        <span class="dnerf">Visual Jenga</span> Starting from an input image, we remove one object at a time while keeping the rest of the scene stable. This process reveals object dependencies and provides a new way to evaluate grounded scene understanding.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p> This paper proposes a novel scene understanding task called Visual Jenga. Drawing inspiration from the game Jenga, the proposed task involves progressively removing objects from a single image until only the background remains. Just as Jenga players must understand structural dependencies to maintain tower stability, our task reveals the intrinsic relationships between scene elements by systematically exploring which objects can be removed while preserving scene coherence in both physical and geometric sense. As a starting point for tackling the Visual Jenga task, we propose a simple, data-driven, training-free approach that is surprisingly effective on a range of real-world images. The principle behind our approach is to utilize the asymmetry in the pairwise relationships between objects within a scene and employ a large inpainting model to generate a set of counterfactuals to quantify the asymmetry.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
<br>
<br>
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Key Idea: Counterfactual Inpainting</h2>
        <img src="./static/images/Inpainting.png" style="width: 100%; display: block; margin: 0 auto;" alt="Inpainting Results">
        <figcaption style="font-size: 0.95em; color: #555; margin-top: 0.5em; text-align: justify;">
          We test how much two objects depend on each other by masking one at a time and using a large inpainting model to fill the missing region. The numbers show similarity between inpainted results and the original object. If replacements vary, the object is less likely to be a support. Here, the table consistently reappears, while the cat is replaced by many objects â€” suggesting the table supports the cat.   </div>
    </div>

    <br>
    <br>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Our Pipeline</h2>
        <img src="./static/images/approach.png" style="width: 100%; display: block; margin: 0 auto;" alt="Inpainting Results">
        <figcaption style="font-size: 0.95em; color: #555; margin-top: 0.5em; text-align: justify;">
          Starting from an input image, we first detect object centers using Molmo. These points are used to segment each object with SAM. We then apply our Counterfactual Inpainting method to rank objects by their dependence, and finally remove them in order using Firefly.  </div>
    </div>
    
    



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{bhattad2025visualjengadiscoveringobject,
      title={Visual Jenga: Discovering Object Dependencies via Counterfactual Inpainting}, 
      author={Anand Bhattad and Konpat Preechakul and Alexei A. Efros},
      year={2025},
      eprint={2503.21770},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.21770}, 
}
</code></pre>
  </div>
</section>


  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
           Website adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> 

</body>
</html>